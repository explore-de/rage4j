"use strict";(self.webpackChunkrage_4_j=self.webpackChunkrage_4_j||[]).push([[483],{8035:(e,n,s)=>{s.r(n),s.d(n,{assets:()=>o,contentTitle:()=>l,default:()=>m,frontMatter:()=>i,metadata:()=>t,toc:()=>c});const t=JSON.parse('{"id":"rage4j-assert/examples","title":"Examples","description":"Example: Testing Answer Correctness","source":"@site/docs/rage4j-assert/examples.md","sourceDirName":"rage4j-assert","slug":"/rage4j-assert/examples","permalink":"/rage4j/docs/rage4j-assert/examples","draft":false,"unlisted":false,"editUrl":"https://github.com/explore-de/rage4j/docs/rage4j-assert/examples.md","tags":[],"version":"current","sidebarPosition":3,"frontMatter":{"title":"Examples","sidebar_position":3},"sidebar":"tutorialSidebar","previous":{"title":"Introduction","permalink":"/rage4j/docs/rage4j-assert/introduction"},"next":{"title":"Contribution","permalink":"/rage4j/docs/contribution"}}');var r=s(4848),a=s(8453);const i={title:"Examples",sidebar_position:3},l=void 0,o={},c=[{value:"Example: Testing Answer Correctness",id:"example-testing-answer-correctness",level:3},{value:"Example: Testing Faithfulness",id:"example-testing-faithfulness",level:3},{value:"Example: Testing Semantic Similarity",id:"example-testing-semantic-similarity",level:3},{value:"Example: Testing Answer Relevance",id:"example-testing-answer-relevance",level:3},{value:"Example: Concatenation of multiple assertions",id:"example-concatenation-of-multiple-assertions",level:3}];function d(e){const n={a:"a",code:"code",h3:"h3",p:"p",pre:"pre",...(0,a.R)(),...e.components};return(0,r.jsxs)(r.Fragment,{children:[(0,r.jsx)(n.h3,{id:"example-testing-answer-correctness",children:"Example: Testing Answer Correctness"}),"\n",(0,r.jsx)(n.pre,{children:(0,r.jsx)(n.code,{className:"language-JAVA",children:"RageAssert rageAssert = new OpenAiLLMBuilder().fromApiKey(key);\nrageAssert.given()\n    .question(QUESTION)\n    .groundTruth(GROUND_TRUTH)\n    .when()\n    .answer(model.generate(QUESTION))\n    .then()\n    .assertAnswerCorrectness(0.7);\n"})}),"\n",(0,r.jsxs)(n.p,{children:["This example demonstrates how to use the ",(0,r.jsx)(n.a,{href:"/docs/rage4j-core/metrics/answer_correctness",children:(0,r.jsx)(n.code,{children:"assertAnswerCorrectness"})}),"\nfeature. It checks if the model's generated answer\nmeets a correctness threshold of 0.7 compared to the defined ground truth."]}),"\n",(0,r.jsx)(n.h3,{id:"example-testing-faithfulness",children:"Example: Testing Faithfulness"}),"\n",(0,r.jsx)(n.pre,{children:(0,r.jsx)(n.code,{className:"language-java",children:"RageAssert rageAssert = new OpenAiLLMBuilder().fromApiKey(key);\nrageAssert.given()\n    .question(QUESTION)\n    .groundTruth(GROUND_TRUTH)\n    .contextList(List.of(ANSWER))\n    .when()\n    .answer(model::generate)\n    .then()\n    .assertFaithfulness(0.7);\n"})}),"\n",(0,r.jsxs)(n.p,{children:["This example illustrates the use of ",(0,r.jsx)(n.a,{href:"/docs/rage4j-core/metrics/faithfulness",children:(0,r.jsx)(n.code,{children:"assertFaithfulness"})}),", ensuring that the\ngenerated answer adheres to the provided\ncontext and retains at least 0.7 faithfulness compared to the ground truth."]}),"\n",(0,r.jsx)(n.h3,{id:"example-testing-semantic-similarity",children:"Example: Testing Semantic Similarity"}),"\n",(0,r.jsx)(n.pre,{children:(0,r.jsx)(n.code,{className:"language-java",children:"RageAssert rageAssert = new OpenAiLLMBuilder().fromApiKey(key);\nrageAssert.given()\n    .question(QUESTION)\n    .groundTruth(GROUND_TRUTH)\n    .when()\n    .answer(model::generate)\n    .then()\n    .assertSemanticSimilarity(0.7);\n"})}),"\n",(0,r.jsxs)(n.p,{children:["In this example, ",(0,r.jsx)(n.a,{href:"/docs/rage4j-core/metrics/answer_semantic_similarity",children:(0,r.jsx)(n.code,{children:"assertSemanticSimilarity"})}),"  is used to verify\nthat the\nsemantic similarity score between the model's\nanswer and the ground truth is at least 0.7."]}),"\n",(0,r.jsx)(n.h3,{id:"example-testing-answer-relevance",children:"Example: Testing Answer Relevance"}),"\n",(0,r.jsx)(n.pre,{children:(0,r.jsx)(n.code,{className:"language-java",children:"RageAssert rageAssert = new OpenAiLLMBuilder().fromApiKey(key);\nrageAssert.given()\n    .question(QUESTION)\n    .groundTruth(GROUND_TRUTH)\n    .contextList(CONTEXT)\n    .when()\n    .answer(model::generate)\n    .then()\n    .assertAnswerRelevance(0.7);\n"})}),"\n",(0,r.jsxs)(n.p,{children:["This example uses the ",(0,r.jsx)(n.a,{href:"/docs/rage4j-core/metrics/answer_relevance",children:(0,r.jsx)(n.code,{children:"assertAnswerRelevance"})})," feature, checking that the\nmodel's answer is relevant to the context\nprovided, with a relevance score of at least 0.7."]}),"\n",(0,r.jsx)(n.h3,{id:"example-concatenation-of-multiple-assertions",children:"Example: Concatenation of multiple assertions"}),"\n",(0,r.jsx)(n.pre,{children:(0,r.jsx)(n.code,{className:"language-java",children:"    RageAssert rageAssert = new OpenAiLLMBuilder().fromApiKey(key);\n    rageAssert.given()\n       .question(QUESTION)\n       .groundTruth(GROUND_TRUTH)\n       .when()\n       .answer(model.generate(QUESTION))\n       .then()\n       .assertAnswerCorrectness(0.7)\n       .then()\n       .assertSemanticSimilarity(0.7);\n"})}),"\n",(0,r.jsx)(n.p,{children:"This example demonstrates how to apply multiple assertions to a single LLM-generated answer.\nAssertions can be chained, allowing you to combine different evaluation metrics such as correctness and semantic similarity.\nThis is the recommended approach for testing one answer against multiple metrics."})]})}function m(e={}){const{wrapper:n}={...(0,a.R)(),...e.components};return n?(0,r.jsx)(n,{...e,children:(0,r.jsx)(d,{...e})}):d(e)}},8453:(e,n,s)=>{s.d(n,{R:()=>i,x:()=>l});var t=s(6540);const r={},a=t.createContext(r);function i(e){const n=t.useContext(a);return t.useMemo((function(){return"function"==typeof e?e(n):{...n,...e}}),[n,e])}function l(e){let n;return n=e.disableParentContext?"function"==typeof e.components?e.components(r):e.components||r:i(e.components),t.createElement(a.Provider,{value:n},e.children)}}}]);